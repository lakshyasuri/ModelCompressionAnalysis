{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cabe8284-d630-47b5-9a88-79eb24722e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from utils import evaluate_model, dynamic_quantization, static_quantization\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models.ResNet50 import ResNet50Baseline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9ae1ef-c1c1-40dd-91f6-75ff8a82175e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qnnpack'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported_engines = torch.backends.quantized.supported_engines\n",
    "if 'qnnpack' in supported_engines:\n",
    "    torch.backends.quantized.engine = 'qnnpack'\n",
    "if 'fbgemm' in supported_engines:\n",
    "    torch.backends.quantized.engine = 'fbgemm'\n",
    "saved_model_path = Path(\"./saved_models/lenet\")\n",
    "torch.backends.quantized.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72da92ba-abfc-4a5c-a610-88ddb3620ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = torch.load(saved_model_path / \"lenet5_baseline_model.pth\", map_location=\"cpu\",weights_only=False)\n",
    "baseline_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2efd6e91-ba1b-41bd-b189-426618a494ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): ConvReLU2d(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv2): ConvReLU2d(\n",
       "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (fc1): DynamicQuantizedLinearReLU(in_features=256, out_features=120, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "  (fc2): DynamicQuantizedLinearReLU(in_features=120, out_features=84, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "  (fc3): DynamicQuantizedLinear(in_features=84, out_features=10, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== dynamic quantisation on baseline model. Uses the function inside the utils.py script\n",
    "quantized_dy_model = dynamic_quantization(baseline_model, (torch.randn(1, 1, 28, 28),))\n",
    "quantized_dy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c74508a7-b31a-4b18-a226-0556bf3f4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(quantized_dy_model.state_dict(), saved_model_path / 'lenet5_base_dy_quant_weights.pth')\n",
    "torch.save(quantized_dy_model, saved_model_path / 'lenet5_base_dy_quant_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07751040-5bee-4a80-8223-1cd1b186d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d90bb4c-4975-42e4-9538-df5af739320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshya/PycharmProjects/ModelCompressionAnalysis/.venv/lib/python3.12/site-packages/torch/_utils.py:431: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): ConvReLU2d(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv2): ConvReLU2d(\n",
       "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (fc1): DynamicQuantizedLinearReLU(in_features=256, out_features=120, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "  (fc2): DynamicQuantizedLinearReLU(in_features=120, out_features=84, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "  (fc3): DynamicQuantizedLinear(in_features=84, out_features=10, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_dy_model = torch.load(saved_model_path / \"lenet5_base_dy_quant_model.pth\", map_location=\"cpu\",weights_only=False)\n",
    "quantized_dy_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3fcdb00-7f49-4d00-ab4f-2499ab039d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 157/157 [00:01<00:00, 143.07it/s, Loss=0.0589, Top1=98.14%]\n"
     ]
    }
   ],
   "source": [
    "baseline_metrics = evaluate_model(baseline_model, test_loader, 'lenet5', high_granularity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd5bd45-303f-4251-9178-f1de2f9ce275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W411 19:07:19.446223000 qlinear_dynamic.cpp:252] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
      "[W411 19:07:19.456742000 qlinear_dynamic.cpp:252] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n",
      "100%|██████████████| 157/157 [00:00<00:00, 166.96it/s, Loss=0.0589, Top1=98.12%]\n"
     ]
    }
   ],
   "source": [
    "baseline_dy_metrics = evaluate_model(quantized_dy_model, test_loader, 'lenet5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b7ac78c-73dc-40d7-ac23-7cb6bd6467e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 16/16 [00:00<00:00, 131.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): QuantizedConvReLU2d(1, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.02737203985452652, zero_point=0)\n",
       "  (conv2): QuantizedConvReLU2d(6, 16, kernel_size=(5, 5), stride=(1, 1), scale=0.047422222793102264, zero_point=0)\n",
       "  (fc1): QuantizedLinearReLU(in_features=256, out_features=120, scale=0.07808518409729004, zero_point=0, qscheme=torch.per_channel_affine)\n",
       "  (fc2): QuantizedLinearReLU(in_features=120, out_features=84, scale=0.06925788521766663, zero_point=0, qscheme=torch.per_channel_affine)\n",
       "  (fc3): QuantizedLinear(in_features=84, out_features=10, scale=0.1696537584066391, zero_point=137, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======= Static Quantization. Uses the function inside the utils.py script\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "calibration_loader = DataLoader(torch.utils.data.Subset(train_dataset, range(1000)), batch_size=64)\n",
    "\n",
    "base_st_quant_model = static_quantization(baseline_model, (torch.randn(1, 1, 28, 28),), \n",
    "                                         calibration_loader)\n",
    "base_st_quant_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1bdb2af-3712-4ce4-a848-291b5ad16045",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(base_st_quant_model.state_dict(), saved_model_path / 'lenet5_base_st_quant_weights.pth')\n",
    "torch.save(base_st_quant_model, saved_model_path / 'lenet5_base_st_quant_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c48d4e3-f013-4b6f-b4d2-be5f50d1c807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 157/157 [00:00<00:00, 160.46it/s, Loss=0.0589, Top1=98.11%]\n"
     ]
    }
   ],
   "source": [
    "baseline_st_metrics = evaluate_model(base_st_quant_model, test_loader, 'lenet5', high_granularity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f0ca867-22a7-4a1a-a822-48da2ef5e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {\n",
    "    \"baseline_metrics\": baseline_metrics,\n",
    "    \"baseline_dy_metrics\": baseline_dy_metrics,\n",
    "    \"baseline_st_metrics\": baseline_st_metrics\n",
    "}\n",
    "metrics_folder = Path(\"./model_metrics/lenet5\")\n",
    "metrics_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fba788fa-71a0-436f-bbe1-7b37754b6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, metrics in all_metrics.items():\n",
    "    with (metrics_folder / f\"{name}.json\").open(\"w\") as file:\n",
    "        json.dump(metrics, file, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9997d316-707a-4943-9dc6-26a134f99c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModelCompressionAnalysis",
   "language": "python",
   "name": "modelcompressionanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
