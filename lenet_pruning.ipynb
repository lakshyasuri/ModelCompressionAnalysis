{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97563a20-57cd-409c-95f7-87279c8a5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from utils import evaluate_model, structured_prune, unstructured_prune\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models.ResNet50 import ResNet50Baseline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fcaf343-1157-4ce2-ae1b-0e38ba10b8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_path = Path(\"./saved_models/lenet\")\n",
    "baseline_model = torch.load(saved_model_path / \"lenet5_baseline_model.pth\", map_location=\"cpu\",weights_only=False)\n",
    "baseline_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fd5482-bc6d-40df-9333-277bf76cb2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True) => (fc1): Linear(in_features=256, out_features=84, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True) => (fc2): Linear(in_features=84, out_features=58, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True) => (fc3): Linear(in_features=58, out_features=10, bias=True)\n",
      ")\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=84, bias=True)\n",
       "  (fc2): Linear(in_features=84, out_features=58, bias=True)\n",
       "  (fc3): Linear(in_features=58, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the passed parameters are best param combinations, we used grid search in a defined search \n",
    "# space with a condition to filter combinations, where accurays drop is less than or equal to 0.02\n",
    "pruned_structured_model = structured_prune(baseline_model, method=\"magnitude\", sparsity=0.3, layer_scope=\"fc\")\n",
    "pruned_structured_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85cb8dd7-d0cb-4bf3-b486-4cdaeec9e3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=84, bias=True)\n",
       "  (fc2): Linear(in_features=84, out_features=58, bias=True)\n",
       "  (fc3): Linear(in_features=58, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_unstructured_model = unstructured_prune(baseline_model, sparsity=0.3, layer_scope=\"fc\")\n",
    "pruned_unstructured_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f6b82a-fd96-4c54-8392-bb270e64e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_structured_model.state_dict(), saved_model_path / 'lenet5_base_str_prune_weights.pth')\n",
    "torch.save(pruned_structured_model, saved_model_path / 'lenet5_base_str_prune_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe236a3f-e6e8-4064-bd84-2a8f89b7953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_unstructured_model.state_dict(), saved_model_path / 'lenet5_base_unstr_prune_weights.pth')\n",
    "torch.save(pruned_unstructured_model, saved_model_path / 'lenet5_base_unstr_prune_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0028590-7206-40a7-9480-d7ac90e8f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "294dbfa4-833f-4f4b-9cec-24fb00289c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=84, bias=True)\n",
       "  (fc2): Linear(in_features=84, out_features=58, bias=True)\n",
       "  (fc3): Linear(in_features=58, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_structured_model = torch.load(saved_model_path / \"lenet5_base_str_prune_model.pth\", map_location=\"cpu\",weights_only=False)\n",
    "pruned_structured_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e56c2f54-4fe0-4e34-b9f2-b67395f90a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 157/157 [00:01<00:00, 83.43it/s, Loss=0.0883, Top1=97.28%]\n"
     ]
    }
   ],
   "source": [
    "baseline_metrics = evaluate_model(baseline_model, test_loader, 'lenet5', high_granularity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f2a5056-998b-4da6-ac46-1a496809912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 157/157 [00:01<00:00, 82.63it/s, Loss=0.0883, Top1=97.28%]\n"
     ]
    }
   ],
   "source": [
    "baseline_str_metrics = evaluate_model(pruned_structured_model, test_loader, 'lenet5', high_granularity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61107720-3539-47d6-a878-9e052e7506f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=84, bias=True)\n",
       "  (fc2): Linear(in_features=84, out_features=58, bias=True)\n",
       "  (fc3): Linear(in_features=58, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_unstructured_model = torch.load(saved_model_path / \"lenet5_base_unstr_prune_model.pth\", map_location=\"cpu\",weights_only=False)\n",
    "pruned_unstructured_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bda08fc-1c48-4169-b8f4-e95e39ef30b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 157/157 [00:01<00:00, 81.27it/s, Loss=0.0883, Top1=97.28%]\n"
     ]
    }
   ],
   "source": [
    "baseline_unstr_metrics = evaluate_model(pruned_unstructured_model, test_loader, 'lenet5', high_granularity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dd0ad5e-0eff-4437-a7e5-23b5d1717da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {\n",
    "    \"baseline_metrics\": baseline_metrics,\n",
    "    \"baseline_str_metrics\": baseline_str_metrics,\n",
    "    \"baseline_unstr_metrics\": baseline_unstr_metrics\n",
    "}\n",
    "metrics_folder = Path(\"./model_metrics/lenet5\")\n",
    "metrics_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b02f72b5-f5a8-48d5-ad9b-dde9bc642c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, metrics in all_metrics.items():\n",
    "    with (metrics_folder / f\"{name}.json\").open(\"w\") as file:\n",
    "        json.dump(metrics, file, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d4141-56fa-44f3-b27b-898f36ba4755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
