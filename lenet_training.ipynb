{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f13dab5-ebb3-4853-9b07-1b63fb297100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.quantization\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torch.quantization.observer import MinMaxObserver, PerChannelMinMaxObserver\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.patches as mpatches\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.onnx\n",
    "import torch_pruning as tp\n",
    "import tempfile\n",
    "from models.LeNet5 import LeNet5\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b822d10-82b4-415d-86ba-e5b847da3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "saved_model_path = Path(\"./saved_models/lenet/\")\n",
    "saved_model_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817a917e-3c01-46e6-ab3f-153672ddb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= Data Preparation\n",
    "torch.manual_seed(42)\n",
    "# === 3. Data ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "calibration_loader = DataLoader(torch.utils.data.Subset(train_dataset, range(1000)), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e8567c3-5266-4a56-84b0-8e68aa28b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= model training function\n",
    "def train_model(model, loader, criterion, epochs):\n",
    "    model.to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    batch_log, image_log = [], []\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (images, labels) in enumerate(tqdm(loader)):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            acc = preds.eq(labels).sum().item() / len(labels)\n",
    "            batch_log.append({\"epoch\": epoch+1, \"batch\": batch_idx, \"loss\": loss.item(), \"accuracy\": acc})\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Batch training loss {loss.item():.4f} | training accuracy {acc:.4f} at step {batch_idx}\")\n",
    "                \n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            confs, pred_labels = probs.max(dim=1)\n",
    "            for i in range(len(images)):\n",
    "                image_log.append({\"epoch\": epoch+1, \"batch\": batch_idx, \"true\": labels[i].item(), \"pred\": pred_labels[i].item(), \"conf\": confs[i].item()})\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c03e71ff-8677-41d0-817e-9305892f55e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏                                          | 5/938 [00:00<00:43, 21.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 2.3090 | training accuracy 0.0625 at step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▌                                    | 104/938 [00:04<00:37, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.3827 | training accuracy 0.8750 at step 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▊                                | 203/938 [00:08<00:32, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.1576 | training accuracy 0.9531 at step 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████▏                           | 302/938 [00:13<00:27, 22.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.1318 | training accuracy 0.9219 at step 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▋                       | 404/938 [00:18<00:24, 22.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0549 | training accuracy 1.0000 at step 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████                   | 504/938 [00:22<00:19, 22.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0864 | training accuracy 0.9531 at step 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████▎              | 603/938 [00:26<00:14, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0951 | training accuracy 0.9531 at step 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████▋          | 702/938 [00:31<00:10, 23.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.1010 | training accuracy 0.9688 at step 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████▏     | 804/938 [00:35<00:05, 23.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0610 | training accuracy 0.9844 at step 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████▍ | 903/938 [00:39<00:01, 22.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0178 | training accuracy 1.0000 at step 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 938/938 [00:41<00:00, 22.61it/s]\n",
      "  0%|▏                                          | 3/938 [00:00<00:33, 28.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0149 | training accuracy 1.0000 at step 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████▍                                    | 102/938 [00:04<00:36, 22.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.1064 | training accuracy 0.9688 at step 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▉                                | 204/938 [00:08<00:30, 23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0231 | training accuracy 1.0000 at step 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████▏                           | 303/938 [00:13<00:25, 25.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0259 | training accuracy 1.0000 at step 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▌                       | 402/938 [00:17<00:23, 23.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.1175 | training accuracy 0.9688 at step 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████                   | 505/938 [00:21<00:18, 23.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0618 | training accuracy 0.9844 at step 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████▍              | 604/938 [00:25<00:13, 24.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0475 | training accuracy 0.9844 at step 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████▋          | 703/938 [00:29<00:10, 23.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0113 | training accuracy 1.0000 at step 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|███████████████████████████████████      | 802/938 [00:34<00:05, 22.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0048 | training accuracy 1.0000 at step 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|███████████████████████████████████████▍ | 902/938 [00:38<00:01, 22.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch training loss 0.0392 | training accuracy 0.9688 at step 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 938/938 [00:40<00:00, 23.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# ====== Baseline Model Training\n",
    "baseline_model = LeNet5()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "baseline_model = train_model(baseline_model, train_loader, criterion, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3bae9181-25b9-4de7-b8fc-b80b3173d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(baseline_model.state_dict(), saved_model_path / 'lenet5_baseline_weights.pth')\n",
    "torch.save(baseline_model, saved_model_path / 'lenet5_baseline_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d798aaa2-7698-4471-85ed-6437ff5e165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qnnpack', 'none']\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.quantized.supported_engines)\n",
    "print(torch.backends.quantized.engine)\n",
    "supported_engines = torch.backends.quantized.supported_engines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e182c-f68c-4e1a-a501-be7c823998c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModelCompressionAnalysis",
   "language": "python",
   "name": "modelcompressionanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
